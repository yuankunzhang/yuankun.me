<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yuankun&#39;s Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yuankun.me/"/>
  <updated>2017-08-13T08:26:16.000Z</updated>
  <id>https://yuankun.me/</id>
  
  <author>
    <name>Yuankun Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>认识时序数据库</title>
    <link href="https://yuankun.me/2017/08/11/introduction-to-tsdb/"/>
    <id>https://yuankun.me/2017/08/11/introduction-to-tsdb/</id>
    <published>2017-08-11T08:54:54.000Z</published>
    <updated>2017-08-13T08:26:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>在很多场景下，数据并不是孤立的存在。例如股票价格的走势，一天之内温度的变化等。一组相关数据以时间为坐标串联起来，形成一条连续的变化线，这就是时序数据。时序数据可以直观地反映变化的规律性，也可以方便地用来识别和预测异常情形。</p>
<p>而时序数据库，就是专门用来存储时序数据的一类特殊数据库。</p>
<p>相比于传统的 RDBMS 或者 NoSQL，时序数据库有下列鲜明的特征。</p>
<a id="more"></a>
<p><strong>时序数据没有复杂的结构和关联</strong>。时序数据关注的是被测指标在时间维度上的变化规律，它并不需要复杂的嵌套的数据结构：时间戳连同数据值就构成了一个数据点。另外，时序数据也不关心不同的被测指标之间的关系（这种关系在定义良好的可视化图表上一目了然），数据之间不需要任何诸如外键等关联关系。</p>
<p><strong>正是因为没有复杂的结构和关联，时序数据库不需要提供范式和事务支持</strong>。时序数据库面向的是与传统数据库截然不同的业务领域，范式和事务在其中是不必要的。不过，时序数据库存在其他的限制和约束。</p>
<p><strong>时序数据库的实时写入量通常很大</strong>。时序数据需要采集的数据量与数据源的数量以及采样的时间精度成正比。在某些业务场景下，一秒钟需要采集上万甚至更多个数据点。</p>
<p><img src="https://i.imgur.com/xBEstlX.png" alt="北京市一天之内的温度走势，图片截取自 www.weather.com.cn"></p>
<p>上图是一组时序数据的示例：北京市一天之内的温度走势，图片截取自 www.weather.com.cn。</p>
<h2 id="时序数据的结构"><a href="#时序数据的结构" class="headerlink" title="时序数据的结构"></a>时序数据的结构</h2><p>时序数据有着简单的结构。</p>
<p>被测量的指标一般称作 <code>metric</code>。指标的一个孤立数据点表示为以指标名为索引的键值对：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">metric -&gt; (timestamp, value)</div></pre></td></tr></table></figure>
<p>依时间顺序逐次采集若干数据点，我们就得到了该被测量指标的一系列值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">metric -&gt; (t0, v0), (t1, v1), (t2, v2), ...</div></pre></td></tr></table></figure>
<p>这就是时序数据的基本结构，一般来说采样的时间间隔是恒定的（允许存在误差）。作为示例，下面是一组温度的时序数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">temperature -&gt; (1502433662000, 29.3), (1502433672002, 29.7), (1502433681999, 29.6), ...</div></pre></td></tr></table></figure>
<p>仅仅依靠指标名称来索引数据略嫌简陋，有时候希望能对数据作出进一步的区分。为了达到这一目的，我们给指标添加一个或者多个标签（labels）。例如，为了区分不同城市的温度，我们引入一个叫做 <code>city</code> 的标签。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">temperature&#123;city=beijing&#125; -&gt; ...</div><div class="line">temperature&#123;city=nanjing&#125; -&gt; ...</div><div class="line">temperature&#123;city=tianjin&#125; -&gt; ...</div></pre></td></tr></table></figure>
<p>指标的名称可以看作是一个叫作 <code>name</code> 的特殊标签，这样，数据的索引就一般化为了一组标签的集合。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&#123;name=temperature, city=beijing&#125; -&gt; ...</div><div class="line">&#123;name=temperature, city=nanjing&#125; -&gt; ...</div><div class="line">&#123;name=temperature, city=tianjin&#125; -&gt; ...</div></pre></td></tr></table></figure>
<h2 id="时序数据库的读写特点"><a href="#时序数据库的读写特点" class="headerlink" title="时序数据库的读写特点"></a>时序数据库的读写特点</h2><p>写入操作的特点：</p>
<ul>
<li>由于数据量庞大，存储时需要引入某种压缩方案。Facebook 在<a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf" target="_blank" rel="external">其阐述 Gorilla 数据库的论文</a>中介绍了一种非常适合时序数据库的压缩方案。</li>
<li>同样由于数据量庞大，存储时应当使用适当的留存策略（Retention Policy），定期删除数据。一般采用三级存储方案：最上层的内存用做缓存，存储热点数据；下一层的 SSD 用来存储留存期（一般为数周或数月）之内的数据；此外还有一个数据中心用来保留全部数据。</li>
<li>写入操作远多于读取操作，可能占到 99% 以上。绝大部分数据不会被用到。</li>
<li>数据总是追加式地写入（顺序写入）。</li>
<li>数据写入之后，就不会再被更新（无随机更新）。</li>
<li>超出留存期的数据被整块删除（无随机删除）。</li>
</ul>
<p>读取操作的特点：</p>
<ul>
<li>时序数据存在显著的时间敏感性，越是近期的数据越重要。大部分读取操作所请求的数据集中在最近一天或几天。</li>
<li>对时序数据的分析过程中需要进行大量运算（求和、计算变化率等），时序数据库需要高效地支持这些运算。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>你可以从以下两篇文章中找到更多关于时序数据库的讨论：</p>
<ul>
<li><a href="http://jmoiron.net/blog/thoughts-on-timeseries-databases/" target="_blank" rel="external">Thoughts on Time-series Databases</a></li>
<li><a href="https://www.xaprb.com/blog/2014/06/08/time-series-database-requirements/" target="_blank" rel="external">Time-Series Database Requirements</a></li>
</ul>
<p>另外，市面上已经有了很多时序数据库，下面两个列表提供了相关方面的内容：</p>
<ul>
<li><a href="https://db-engines.com/en/ranking/time+series+dbms" target="_blank" rel="external">DB-Engines Ranking of Time Series DBMS</a></li>
<li><a href="The complete list of all time series databases for your IoT project">The complete list of all time series databases for your IoT project</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在很多场景下，数据并不是孤立的存在。例如股票价格的走势，一天之内温度的变化等。一组相关数据以时间为坐标串联起来，形成一条连续的变化线，这就是时序数据。时序数据可以直观地反映变化的规律性，也可以方便地用来识别和预测异常情形。&lt;/p&gt;
&lt;p&gt;而时序数据库，就是专门用来存储时序数据的一类特殊数据库。&lt;/p&gt;
&lt;p&gt;相比于传统的 RDBMS 或者 NoSQL，时序数据库有下列鲜明的特征。&lt;/p&gt;
    
    </summary>
    
    
      <category term="tsdb" scheme="https://yuankun.me/tags/tsdb/"/>
    
  </entry>
  
  <entry>
    <title>使用 Let&#39;s Encrypt 为网站启用 HTTPS 支持</title>
    <link href="https://yuankun.me/2017/08/06/enable-https-with-lets-encrypt/"/>
    <id>https://yuankun.me/2017/08/06/enable-https-with-lets-encrypt/</id>
    <published>2017-08-06T08:58:13.000Z</published>
    <updated>2017-08-13T08:31:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>HTTP 协议传输的数据都是不加密的。想象一下，你访问某个网站，当数据经过路由器、宽带网关，以及某墙的时候都是完全可见的，是不是有种裸奔的感觉？为网站启用 HTTPS 支持可以说是大势所趋，在某国日益倒车的互联网环境下更是如此。</p>
<p>第零步是选择一个靠谱的 CA（Certificate Authority，数字证书认证中心）。你以为所有的认证中心都是中立可信的吗？并不是的，比如此前频频爆出丑闻的 WoSign 和 StarCom，这两家认证中心<a href="https://security.googleblog.com/2016/10/distrusting-wosign-and-startcom.html" target="_blank" rel="external">已经被 Google Chrome 等多款浏览器默认设置为不信任</a>。当然你更不能自己做裁判，像 12306.cn 一样给自己颁发证书。这里推荐 <a href="https://letsencrypt.org/" target="_blank" rel="external">Let’s Encrypt</a>，这家成立于 2016 年、由互联网安全研究小组（ISRG）主导的机构致力于向用户提供<strong>免费的、自动化管理</strong>的证书方案。</p>
<a id="more"></a>
<p>Let’s Encrypt 允许使用实现了 <a href="https://ietf-wg-acme.github.io/acme/" target="_blank" rel="external">ACME 协议</a>的客户端完成诸如证书获取、认证、签名、安装以及续签等步骤。官方推荐使用 <a href="https://certbot.eff.org/" target="_blank" rel="external">Certbot</a>。下面，我们以 Ubuntu 16.04 &amp; Nginx 为例，说明如何使用 Certbot 快速地为网站启用 HTTPS 支持。</p>
<h2 id="第一步：安装-Certbot"><a href="#第一步：安装-Certbot" class="headerlink" title="第一步：安装 Certbot"></a>第一步：安装 Certbot</h2><p>在系统中添加 Certbot 的 PPA，然后使用 <code>apt</code> 安装 Certbot。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> sudo apt-get update</div><div class="line"><span class="meta">$</span> sudo apt-get install software-properties-common</div><div class="line"><span class="meta">$</span> sudo add-apt-repository ppa:certbot/certbot</div><div class="line"><span class="meta">$</span> sudo apt-get update</div><div class="line"><span class="meta">$</span> sudo apt-get install python-certbot-nginx</div></pre></td></tr></table></figure>
<h2 id="第二步：安装证书"><a href="#第二步：安装证书" class="headerlink" title="第二步：安装证书"></a>第二步：安装证书</h2><p>运行下面的命令获取证书，这个命令同时会为你更改 Nginx 配置文件（并且重载 Nginx）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> sudo certbot --nginx</div></pre></td></tr></table></figure>
<p>如果你想自己修改 Nginx 配置文件，可以使用 <code>certonly</code> 选项：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> sudo certbot --nginx certonly</div></pre></td></tr></table></figure>
<h2 id="第三步：自动续签"><a href="#第三步：自动续签" class="headerlink" title="第三步：自动续签"></a>第三步：自动续签</h2><p>Let’s Encrypt 签发的证书，有效期是 90 天。你可以使用下面的命令对证书进行续签：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> sudo certbot renew --dry-run</div></pre></td></tr></table></figure>
<p>当然，创建一个 Cron Job 周期性地自动续签是一个更省事的方案。</p>
<hr>
<p>现在，在浏览器中打开你的网站，你就能从地址栏看到令人安心的绿色小锁了。除了本文介绍的方法，<a href="https://github.com/Neilpang/acme.sh" target="_blank" rel="external">acme.sh</a> 这个项目也提供了一种非常易用的方案。想要了解更多，请参考<a href="https://syntaxoff.com/post/201708/domain_ssl/" target="_blank" rel="external">这篇文章</a>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HTTP 协议传输的数据都是不加密的。想象一下，你访问某个网站，当数据经过路由器、宽带网关，以及某墙的时候都是完全可见的，是不是有种裸奔的感觉？为网站启用 HTTPS 支持可以说是大势所趋，在某国日益倒车的互联网环境下更是如此。&lt;/p&gt;
&lt;p&gt;第零步是选择一个靠谱的 CA（Certificate Authority，数字证书认证中心）。你以为所有的认证中心都是中立可信的吗？并不是的，比如此前频频爆出丑闻的 WoSign 和 StarCom，这两家认证中心&lt;a href=&quot;https://security.googleblog.com/2016/10/distrusting-wosign-and-startcom.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;已经被 Google Chrome 等多款浏览器默认设置为不信任&lt;/a&gt;。当然你更不能自己做裁判，像 12306.cn 一样给自己颁发证书。这里推荐 &lt;a href=&quot;https://letsencrypt.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Let’s Encrypt&lt;/a&gt;，这家成立于 2016 年、由互联网安全研究小组（ISRG）主导的机构致力于向用户提供&lt;strong&gt;免费的、自动化管理&lt;/strong&gt;的证书方案。&lt;/p&gt;
    
    </summary>
    
    
      <category term="ssl" scheme="https://yuankun.me/tags/ssl/"/>
    
      <category term="security" scheme="https://yuankun.me/tags/security/"/>
    
  </entry>
  
  <entry>
    <title>为 Prometheus 添加 HTTP Basic Auth</title>
    <link href="https://yuankun.me/2017/07/30/add-http-basic-auth-to-prometheus/"/>
    <id>https://yuankun.me/2017/07/30/add-http-basic-auth-to-prometheus/</id>
    <published>2017-07-30T15:03:44.000Z</published>
    <updated>2017-08-13T08:42:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>Prometheus 的 <a href="https://github.com/prometheus/node_exporter" target="_blank" rel="external">Node Exporter</a> 并没有提供任何认证支持。不过，借助 Nginx 作为反向代理服务器，我们可以很容易地为 Node Exporter 添加 HTTP Basic Auth 功能。</p>
<p>首先，启动 Node Exporter，监听 9090 端口。</p>
<p>然后，在 <code>/etc/nginx</code> （可能你的 Nginx 配置目录在其他路径，请做相应修改）目录下，使用 <code>apache2-utils</code> 提供的 <code>htpasswd</code> 工具创建一个用户文件，需要填入用户名和密码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> htpasswd -c .htpasswd yuankun</div><div class="line">New password: </div><div class="line">Re-type new password: </div><div class="line">Adding password for user yuankun</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>接下来，在 Nginx 配置文件中添加下面的配置，这里我们使用 19090 作为代理端口：</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="section">http</span> &#123;</div><div class="line">  <span class="section">server</span> &#123;</div><div class="line">    <span class="attribute">listen</span> <span class="number">0.0.0.0:19090</span>;</div><div class="line">    <span class="attribute">location</span> / &#123;</div><div class="line">      <span class="attribute">proxy_pass</span> http://localhost:9090/;</div><div class="line"></div><div class="line">      <span class="attribute">auth_basic</span> <span class="string">"Prometheus"</span>;</div><div class="line">      <span class="attribute">auth_basic_user_file</span> <span class="string">".htpasswd"</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>保存配置文件，然后重新载入 Nginx 服务。此时在浏览器中访问 server:19090，浏览器会要求你输入用户名和密码。</p>
<p>最后一步是修改 <code>prometheus.yml</code> 文件，将我们的 Node Exporter 服务添加进去：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="attr">- job_name:</span> <span class="string">'node-exporter'</span></div><div class="line"><span class="attr">  static_configs:</span></div><div class="line"><span class="attr">    - targets:</span> <span class="string">['your-ip:19090']</span></div><div class="line"><span class="attr">  basic_auth:</span></div><div class="line"><span class="attr">    username:</span> <span class="string">yuankun</span></div><div class="line"><span class="attr">    password:</span> <span class="string">your-password</span></div></pre></td></tr></table></figure>
<p>重启 Prometheus 服务，就大功告成了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Prometheus 的 &lt;a href=&quot;https://github.com/prometheus/node_exporter&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Node Exporter&lt;/a&gt; 并没有提供任何认证支持。不过，借助 Nginx 作为反向代理服务器，我们可以很容易地为 Node Exporter 添加 HTTP Basic Auth 功能。&lt;/p&gt;
&lt;p&gt;首先，启动 Node Exporter，监听 9090 端口。&lt;/p&gt;
&lt;p&gt;然后，在 &lt;code&gt;/etc/nginx&lt;/code&gt; （可能你的 Nginx 配置目录在其他路径，请做相应修改）目录下，使用 &lt;code&gt;apache2-utils&lt;/code&gt; 提供的 &lt;code&gt;htpasswd&lt;/code&gt; 工具创建一个用户文件，需要填入用户名和密码：&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;$&lt;/span&gt; htpasswd -c .htpasswd yuankun&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;New password: &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Re-type new password: &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Adding password for user yuankun&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="prometheus" scheme="https://yuankun.me/tags/prometheus/"/>
    
  </entry>
  
  <entry>
    <title>规划 Prometheus 的存储用量</title>
    <link href="https://yuankun.me/2017/05/03/plan-storage-space-for-prometheus/"/>
    <id>https://yuankun.me/2017/05/03/plan-storage-space-for-prometheus/</id>
    <published>2017-05-03T14:32:30.000Z</published>
    <updated>2017-08-13T09:14:57.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-引言"><a href="#一-引言" class="headerlink" title="一. 引言"></a>一. 引言</h2><p><a href="https://prometheus.io/" target="_blank" rel="external">Prometheus</a> 是一款开源的监控与报警系统，支持对海量监控数据的抓取与查询。在部署 Prometheus 服务之前，对服务的存储用量进行规划是十分重要的。否则，运维人员无法对业务数据的规模和所需存储资源的量级获得直观认识。分配的存储资源过多，会导致资源闲置与成本浪费；分配的存储容量不足，则无法应对业务的增长，严重影响监控服务的稳定性。</p>
<p>部署 Prometheus 服务的第一个步骤是，整理与获得需要监控的节点集合。通过这一集合，我们可以计算出业务数据的规模。进而，我们可以计算出，需要多少存储资源来支撑监控服务的运行。</p>
<p>本文对影响 Prometheus 服务的运行时存储用量的各个因素进行了剖析与讨论，并给出若干经验公式。这些公式可以用于预估监控服务的内存和硬盘用量。</p>
<a id="more"></a>
<h2 id="二-计算样本总量"><a href="#二-计算样本总量" class="headerlink" title="二. 计算样本总量"></a>二. 计算样本总量</h2><p>首先明确两个名词，监控节点与测量点。</p>
<ul>
<li><strong>监控节点</strong>。一个 <a href="https://prometheus.io/docs/instrumenting/exporters/" target="_blank" rel="external">exporter</a> 进程被认为是一个监控节点。一台主机上可能运行多个不同类型的 exporter，因此，这台主机上存在多个监控节点。</li>
<li><strong>测量点</strong>。一个测量点代表了某监控节点上的一个观测对象。从某测量点采集到的一组样本数据构成一条时间序列（time series）。</li>
</ul>
<p>为了预估存储用量，首先需要计算样本数据的总量。我们约定：</p>
<ul>
<li>需要监控的节点集合为 $nodes={i|i&gt;0}$</li>
<li>节点 $i$ 上的测量点的数目为 $metrics(i)$ </li>
<li>对节点 $i$ 的抓取时间间隔为 $interval(i)$，一般为所有节点设置相同的抓取间隔</li>
</ul>
<p>每个节点上的测量点的数目由所使用的具体的 exporter 定义。特别的：</p>
<ul>
<li><a href="https://github.com/prometheus/node_exporter" target="_blank" rel="external">Node Exporter</a> 大约有 250 个测量点</li>
<li>Prometheus 服务本身大约有 770 个测量点</li>
</ul>
<p>抓取间隔越大，数据越稀疏；抓取间隔越小，监控数据的时间分辨率越高，但所需的存储资源会增多。<strong>建议将该值设置在 5s ~ 15s 之间</strong>。</p>
<p>基于上述约定可得，在特定的时间范围 $duration$ 内，Prometheus 从节点集合中所抓取的样本数据的总量依下式计算：</p>
<p>$$sample\_count(duration)=\sum_{i \in nodes}{(metrics(i) \times \frac{duration}{interval(i)})}$$</p>
<p>Prometheus 支持三种不同的数据编码方案。第一种方案是 delta 编码，已被弃用；第二种方案是 double-delta 编码，这也是默认使用的编码方案；第三种方案是 varbit 编码，基于 Facebook 的<a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf" target="_blank" rel="external">一篇关于时序数据库的论文</a>。varbit 编码方案虽能提高数据压缩率，却显著增大了编解码的运算时间。除非有特殊场景，否则我们使用 double-delta 编码方案。</p>
<p>由 Prometheus 的<a href="https://prometheus.io/docs/operating/storage/#chunk-encoding" target="_blank" rel="external">官方文档</a>，使用 double-delta 方案对数据进行编码后，每条样本的字节大小为：</p>
<p>$$sample\_size=3.3B$$</p>
<p>经过若干次采样测量，观测到的平均样本大小介于 3.0~3.8B 之间。可以认为 3.3B 的单条样本大小是可信的。</p>
<h2 id="三-规划内存用量"><a href="#三-规划内存用量" class="headerlink" title="三. 规划内存用量"></a>三. 规划内存用量</h2><p>Prometheus 对内存的使用由以下四个部分组成：</p>
<ol>
<li>留存于内存的活跃样本</li>
<li>排队等待持久化的过期样本</li>
<li>索引数据</li>
<li>其他运行时内存消耗</li>
</ol>
<p>第 3.1 节讨论样本数据的内存用量（前两部分），第 3.2 节讨论索引数据的内存用量。对于其他的运行时内存消耗，本文不予讨论。</p>
<h3 id="3-1-为样本数据计算内存用量"><a href="#3-1-为样本数据计算内存用量" class="headerlink" title="3.1 为样本数据计算内存用量"></a>3.1 为样本数据计算内存用量</h3><p><strong>3.1.1 留存于内存的活跃样本</strong></p>
<p>对于活跃样本，假设我们要求的留存时间为 $mem\_retention$，则所需的内存空间为：</p>
<p>$$sample\_mem\_1=sample\_size \times sample\_count(mem\_retention)$$</p>
<p>在内存中的留存数据越多，查询过往数据的性能越高。但是，新数据的价值远远高于过往数据。在实际应用中，需要根据所监控的业务的性质，设定合理的内存留存时间。Facebook 在<a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf" target="_blank" rel="external">其论文</a>中给出的经验值是 26h。<strong>建议将该值设置在 6h ~ 48h 之间</strong>。</p>
<p><strong>3.1.2 排队等待持久化的过期样本</strong></p>
<p>对于排队样本，我们约定：</p>
<ul>
<li>为了完成对当前所有排队样本的持久化，Prometheus 需要花费的时间周期为 $persist\_cycle$</li>
<li>为了不至于使 Prometheus 进入紧急模式（Rush mode），排队样本所占的空间不应超过预估空间的 $80\%$</li>
</ul>
<p>一般情况下，持久化的时间周期为 6 个小时：</p>
<p>$$persist\_cycle=6h$$</p>
<p>因此，排队样本所需的内存空间为：</p>
<p>$$sample\_mem\_2=\frac{sample\_size \times sample\_count(persist\_cycle)}{0.8}$$</p>
<p><strong>3.1.3 汇总</strong></p>
<p>基于前两个公式，再加上索引数据的内存用量（参见第 3.2 节），总内存用量可以依下式计算：</p>
<p>$$mem=sample\_mem\_1+sample\_mem\_2+index\_mem$$</p>
<p>一条<a href="https://prometheus.io/docs/operating/storage/#memory-usage" target="_blank" rel="external">经验法则</a>为，<strong>总内存用量不应超过物理内存大小的三分之二</strong>。</p>
<p>下表计算了若干典型的内存用量（假设所有节点均为 Node Exporter 节点）：</p>
<table>
<thead>
<tr>
<th><strong>节点数目</strong></th>
<th><strong>内存留存</strong></th>
<th><strong>抓取间隔</strong></th>
<th><strong>活跃样本量</strong></th>
<th><strong>排队样本量</strong></th>
<th><strong>内存用量</strong></th>
<th><strong>物理内存</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>100</td>
<td>6h</td>
<td>1s</td>
<td>1.789G</td>
<td>2.237G</td>
<td>4.026G</td>
<td>6G</td>
</tr>
<tr>
<td>100</td>
<td>6h</td>
<td>5s</td>
<td>0.358G</td>
<td>0.447G</td>
<td>0.805G</td>
<td>1.5G</td>
</tr>
<tr>
<td>1000</td>
<td>6h</td>
<td>5s</td>
<td>3.58G</td>
<td>0.447G</td>
<td>4.027G</td>
<td>6G</td>
</tr>
<tr>
<td>100</td>
<td>24h</td>
<td>1s</td>
<td>7.156G</td>
<td>2.237G</td>
<td>9.393G</td>
<td>14G</td>
</tr>
<tr>
<td>100</td>
<td>24h</td>
<td>5s</td>
<td>1.432G</td>
<td>0.447G</td>
<td>1.879G</td>
<td>3G</td>
</tr>
<tr>
<td>1000</td>
<td>24h</td>
<td>5s</td>
<td>14.32G</td>
<td>0.447G</td>
<td>14.75G</td>
<td>22G</td>
</tr>
</tbody>
</table>
<h3 id="3-2-为索引数据计算内存用量"><a href="#3-2-为索引数据计算内存用量" class="headerlink" title="3.2 为索引数据计算内存用量"></a>3.2 为索引数据计算内存用量</h3><p>对索引数据所需内存的估计，可以使用下面的经验公式：</p>
<p>$$index\_mem=\frac{series\_count}{1000}MB$$</p>
<p>其中，</p>
<p>$$series\_count=\sum_{i \in nodes}{metrics(i)}$$</p>
<p>也就是，如果有 1000 个时间序列，大约需要 1M 内存。为了提高对旧数据查询性能，可以适当增大索引内存。</p>
<h2 id="四-规划硬盘用量"><a href="#四-规划硬盘用量" class="headerlink" title="四. 规划硬盘用量"></a>四. 规划硬盘用量</h2><h3 id="4-1-为样本数据计算硬盘用量"><a href="#4-1-为样本数据计算硬盘用量" class="headerlink" title="4.1 为样本数据计算硬盘用量"></a>4.1 为样本数据计算硬盘用量</h3><p>Prometheus 将样本数据持久化为若干文件。当文件中的过期数据超过一定比率时，Prometheus 会对文件执行收缩操作。这个比率被称为文件的收缩比，默认值为 $10\%$。留存时间设置的越大，文件的收缩比应该相应地上调。</p>
<p>假设我们要求样本留存时间为 $disk\_retension$，文件的收缩比为 $shrink\_ratio$，则样本的硬盘用量为：</p>
<p>$$sample\_disk=\frac{sample\_size \times sample\_count(disk\_retention)}{1+shrink\_ratio}$$</p>
<p>加上存储检查点所需的硬盘空间（参加第 4.2 节），总硬盘用量为：</p>
<p>$$disk=sample\_disk+checkpoint\_disk$$</p>
<p>下表计算了若干典型的硬盘用量（假设所有节点均为 Node Exporter 节点），注意，该表未包含存储 checkpoint 所需要的硬盘空间：</p>
<table>
<thead>
<tr>
<th><strong>节点数目</strong></th>
<th><strong>留存时间</strong></th>
<th><strong>抓取间隔</strong></th>
<th><strong>硬盘用量</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>100</td>
<td>14d</td>
<td>1s</td>
<td>91G</td>
</tr>
<tr>
<td>100</td>
<td>14d</td>
<td>5s</td>
<td>18G</td>
</tr>
<tr>
<td>1000</td>
<td>14d</td>
<td>1s</td>
<td>910G</td>
</tr>
<tr>
<td>1000</td>
<td>14d</td>
<td>5s</td>
<td>180G</td>
</tr>
</tbody>
</table>
<h3 id="4-2-为检查点（Checkpoint）计算硬盘用量"><a href="#4-2-为检查点（Checkpoint）计算硬盘用量" class="headerlink" title="4.2 为检查点（Checkpoint）计算硬盘用量"></a>4.2 为检查点（Checkpoint）计算硬盘用量</h3><p>检查点操作用于将内存中的活跃样本暂存到某硬盘文件中，以减少由于程序崩溃或机器掉电等引起的数据丢失。其硬盘用量与活跃样本的内存用量持平即可：</p>
<p>$$checkpoint\_disk=sample\_mem\_1$$</p>
<h2 id="五-总结"><a href="#五-总结" class="headerlink" title="五. 总结"></a>五. 总结</h2><p>本文中，我们首先讨论了如何计算所观测的样本总量。特别的，Node Exporter 大约有 250 个测量点，Prometheus 服务本身大约有 770 个测量点。</p>
<p>进行内存用量规划时，我们主要关注留存于内存中的活跃样本与位于持久化队列中的过期样本。索引数据所需的内存较少，一个经验公式为，每一千个时间序列大约需要 1M 内存。</p>
<p>Prometheus 对硬盘的使用主要集中在对样本数据的持久化上。当文件过大时，Prometheus 会对文件执行收缩操作。收缩操作的触发由文件的收缩比控制，该选项的默认值为 $10\%$。</p>
<p>请注意，数据对内存和硬盘的使用情况由众多因素共同影响，例如，数据本身的性质，内存性能，硬盘性能，垃圾回收机制，内存碎片等。对存储用量作出准确的预估是困难的。本文给出的公式在评估数据量级时有参考意义，对于实际的调优工作，还需要对线上环境进行深入而详尽的观察和测量之后方可完成。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一-引言&quot;&gt;&lt;a href=&quot;#一-引言&quot; class=&quot;headerlink&quot; title=&quot;一. 引言&quot;&gt;&lt;/a&gt;一. 引言&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://prometheus.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Prometheus&lt;/a&gt; 是一款开源的监控与报警系统，支持对海量监控数据的抓取与查询。在部署 Prometheus 服务之前，对服务的存储用量进行规划是十分重要的。否则，运维人员无法对业务数据的规模和所需存储资源的量级获得直观认识。分配的存储资源过多，会导致资源闲置与成本浪费；分配的存储容量不足，则无法应对业务的增长，严重影响监控服务的稳定性。&lt;/p&gt;
&lt;p&gt;部署 Prometheus 服务的第一个步骤是，整理与获得需要监控的节点集合。通过这一集合，我们可以计算出业务数据的规模。进而，我们可以计算出，需要多少存储资源来支撑监控服务的运行。&lt;/p&gt;
&lt;p&gt;本文对影响 Prometheus 服务的运行时存储用量的各个因素进行了剖析与讨论，并给出若干经验公式。这些公式可以用于预估监控服务的内存和硬盘用量。&lt;/p&gt;
    
    </summary>
    
    
      <category term="prometheus" scheme="https://yuankun.me/tags/prometheus/"/>
    
  </entry>
  
  <entry>
    <title>隐藏在素数无穷的证明中的一个陷阱</title>
    <link href="https://yuankun.me/2017/02/03/trap-in-euclids-proof-of-primes/"/>
    <id>https://yuankun.me/2017/02/03/trap-in-euclids-proof-of-primes/</id>
    <published>2017-02-03T13:42:50.000Z</published>
    <updated>2017-08-13T09:25:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道，关于素数有无穷多个的最普遍的证明方法是欧几里得的反证法：</p>
<blockquote>
<p>假设存在最大的素数 P，那么我们可以基于所有的素数构造一个新的数 $Q = 2 \times 3 \times 5 \times 7 \times … \times P + 1$。显然这个数不能被任一素数整除（所有素数除它都余1），这说明我们找到了一个更大的素数。</p>
</blockquote>
<p>我发现很多人误认为我们构造的这个新数 Q 是一个素数（甚至有些数学教材上也这么写），这其实是不对的。基于 Q 不能被任意素数整除这一事实，我们无法推断 Q 是否为素数，仅能够得到下面的结论：Q 或者是一个素数，或者包含一个比最大的素数 P 更大的素数因子。</p>
<p>通过简单的几行程序就能找到”存在 Q 为合数“的证据。这个数并不大。当 P 为 13 时，$Q = 2 \times 3 \times 5 \times 7 \times 11 \times 13 +1 = 30031 = 59 \times 509$。</p>
<a id="more"></a>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们知道，关于素数有无穷多个的最普遍的证明方法是欧几里得的反证法：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假设存在最大的素数 P，那么我们可以基于所有的素数构造一个新的数 $Q = 2 \times 3 \times 5 \times 7 \times … \times P + 1$。显然这个数不能被任一素数整除（所有素数除它都余1），这说明我们找到了一个更大的素数。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我发现很多人误认为我们构造的这个新数 Q 是一个素数（甚至有些数学教材上也这么写），这其实是不对的。基于 Q 不能被任意素数整除这一事实，我们无法推断 Q 是否为素数，仅能够得到下面的结论：Q 或者是一个素数，或者包含一个比最大的素数 P 更大的素数因子。&lt;/p&gt;
&lt;p&gt;通过简单的几行程序就能找到”存在 Q 为合数“的证据。这个数并不大。当 P 为 13 时，$Q = 2 \times 3 \times 5 \times 7 \times 11 \times 13 +1 = 30031 = 59 \times 509$。&lt;/p&gt;
    
    </summary>
    
    
      <category term="math" scheme="https://yuankun.me/tags/math/"/>
    
  </entry>
  
</feed>
